---
title: "Biostat 203B Homework 1"
subtitle: Due Jan 24, 2024 @ 11:59PM
author: Palash Raval and 406551574
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
    link-external-icon: true
    link-external-newwindow: true
---

Display machine information for reproducibility:
```{r}
#| eval: true
sessionInfo()
```

## Q1. Git/GitHub

**No handwritten homework reports are accepted for this course.** We work with Git and GitHub. Efficient and abundant use of Git, e.g., frequent and well-documented commits, is an important criterion for grading your homework.

1. Apply for the [Student Developer Pack](https://education.github.com/pack) at GitHub using your UCLA email. You'll get GitHub Pro account for free (unlimited public and private repositories).

2. Create a **private** repository `biostat-203b-2025-winter` and add `Hua-Zhou` and TA team (`Tomoki-Okuno` for Lec 1; `parsajamshidian` and `BowenZhang2001` for Lec 82) as your collaborators with write permission.

3. Top directories of the repository should be `hw1`, `hw2`, ... Maintain two branches `main` and `develop`. The `develop` branch will be your main playground, the place where you develop solution (code) to homework problems and write up report. The `main` branch will be your presentation area. Submit your homework files (Quarto file `qmd`, `html` file converted by Quarto, all code and extra data sets to reproduce results) in the `main` branch.

4. After each homework due date, course reader and instructor will check out your `main` branch for grading. Tag each of your homework submissions with tag names `hw1`, `hw2`, ... Tagging time will be used as your submission time. That means if you tag your `hw1` submission after deadline, penalty points will be deducted for late submission.

5. After this course, you can make this repository public and use it to demonstrate your skill sets on job market.

**Solution: Done**

## Q2. Data ethics training

This exercise (and later in this course) uses the [MIMIC-IV data v3.1](https://physionet.org/content/mimiciv/3.1/), a freely accessible critical care database developed by the MIT Lab for Computational Physiology. Follow the instructions at <https://mimic.mit.edu/docs/gettingstarted/> to (1) complete the CITI `Data or Specimens Only Research` course and (2) obtain the PhysioNet credential for using the MIMIC-IV data. Display the verification links to your completion report and completion certificate here. **You must complete Q2 before working on the remaining questions.** (Hint: The CITI training takes a few hours and the PhysioNet credentialing takes a couple days; do not leave it to the last minute.)

Here is the [Completion Certificate](https://www.citiprogram.org/verify/?wc552ff09-b10f-43fb-bcdc-2458a785c674-67239600)

Here is the [Completion Report](https://www.citiprogram.org/verify/?kf7af8d06-4f6f-4487-8157-46ac6c7329bc-67239600)


## Q3. Linux Shell Commands

1. Make the MIMIC-IV v3.1 data available at location `~/mimic`. The output of the `ls -l ~/mimic` command should be similar to the below (from my laptop).
```{bash}
#| eval: true
# content of mimic folder
ls -l ~/mimic/
```
Refer to the documentation <https://physionet.org/content/mimiciv/3.1/> for details of data files. Do **not** put these data files into Git; they are big. Do **not** copy them into your directory. Do **not** decompress the gz data files. These create unnecessary big files and are not big-data-friendly practices. Read from the data folder `~/mimic` directly in following exercises. 

  Use Bash commands to answer following questions.

2. Display the contents in the folders `hosp` and `icu` using Bash command `ls -l`. Why are these data files distributed as `.csv.gz` files instead of `.csv` (comma separated values) files? Read the page <https://mimic.mit.edu/docs/iv/> to understand what's in each folder.

```{bash}
ls -l ~/mimic/hosp
```
```{bash}
ls -l ~/mimic/icu
```

**Solution: Both icu and hosp contain large amounts of data. Hosp contains detailed information about the patient at a hospital-level, while icu contains detailed information about ICU admissions. Due to the large volume of data, the data files must be compressed in order to reduce the overall size of the data files, which is why they are .csv.gz and not just .csv** 


3. Briefly describe what Bash commands `zcat`, `zless`, `zmore`, and `zgrep` do.

**Solution: 'zcat' allows for the viewing of compressed files(.gz) without requiring the decompressing of the file first. 'zless' also allows for the viewing of compressed files, but is done so in a way that scrolling is utilized to scan through the entire text in the data file. 'zmore' allows for the viewing of compressed files in one large chunk at a time. 'zgrep' helps with searching through a compressed file for a specific text within the file in question.**


4. (Looping in Bash) What's the output of the following bash script?
```{bash}
#| eval: false
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
do
  ls -l $datafile
done
```

**Solution: The output of the script gives 3 files: 'admissions.csv.gz', 'labevents.csv.gz', and 'patients.csv.gz'.** 


Display the number of lines in each data file using a similar loop. (Hint: combine linux commands `zcat <` and `wc -l`.)

```{bash}
#| eval: false
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
do
  zcat < $datafile | wc -l
done
```

**Solution: 'admissions.csv.gz' has 546029 lines, 'labevents.csv.gz' has 158374765 lines , and 'patients.csv.gz' has 364628 lines.**


5. Display the first few lines of `admissions.csv.gz`. How many rows are in this data file, excluding the header line? Each `hadm_id` identifies a hospitalization. How many hospitalizations are in this data file? How many unique patients (identified by `subject_id`) are in this data file? Do they match the number of patients listed in the `patients.csv.gz` file? (Hint: combine Linux commands `zcat <`, `head`/`tail`, `awk`, `sort`, `uniq`, `wc`, and so on.)

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | head -5
```
**Solution: Above is the first 5 lines of the 'admissions.csv.gz' file.**

```{bash}

zcat < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | wc -l

```

**Solution: There are 546028 rows in the 'admissions.csv.gz' file without the header line.**

```{bash}

zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, '{print $2}' | tail -n +2 | sort | uniq | wc -l  

```       

**Solution: There are 546028 hospitalizations in this data file.**

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, '{print $1}' | tail -n +2 | uniq | wc -l  
```

```{bash}
zcat < ~/mimic/hosp/patients.csv.gz | awk -F, '{print $1}' | tail -n +2 | uniq | wc -l  
```

**Solution: There are 223452 unique patients in the 'admissions.csv.gz' data file. No, it does not match the number of patients in the 'patients.csv.gz' data file since it had 364627 unique values.**


6. What are the possible values taken by each of the variable `admission_type`, `admission_location`, `insurance`, and `ethnicity`? Also report the count for each unique value of these variables in decreasing order. (Hint: combine Linux commands `zcat`, `head`/`tail`, `awk`, `uniq -c`, `wc`, `sort`, and so on; skip the header line.)

```{bash}

zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, '{print $6}' | tail -n +2 | sort | uniq -c | sort -nr

```

```{bash}

zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, '{print $8}' | tail -n +2 | sort | uniq -c | sort -nr

```

```{bash}

zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, '{print $10}' | tail -n +2 | sort | uniq -c | sort -nr

```

```{bash}

zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, '{print $13}' | tail -n +2 | sort | uniq -c | sort -nr

```

**Solution: Above are all the possible values and the number of appearances of each for 4 columns in the 'admissions.csv.gz' data file(`admission_type`, `admission_location`, `insurance`, and `race`).** 


7. The `icusays.csv.gz` file contains all the ICU stays during the study period. How many ICU stays, identified by `stay_id`, are in this data file? How many unique patients, identified by `subject_id`, are in this data file?

```{bash}

zcat < ~/mimic/icu/icustays.csv.gz | awk -F, '{print $3}' | tail -n +2 | uniq | wc -l 

```

```{bash}
zcat < ~/mimic/icu/icustays.csv.gz | awk -F, '{print $1}' | tail -n +2 | uniq | wc -l 
```

**Solution: There are 94458 icu stays and there are 65366 unique patients in this data file.**


8. _To compress, or not to compress. That's the question._ Let's focus on the big data file `labevents.csv.gz`. Compare compressed gz file size to the uncompressed file size. Compare the run times of `zcat < ~/mimic/labevents.csv.gz | wc -l` versus `wc -l labevents.csv`. Discuss the trade off between storage and speed for big data files. (Hint: `gzip -dk < FILENAME.gz > ./FILENAME`. Remember to delete the large `labevents.csv` file after the exercise.)





## Q4. Who's popular in Price and Prejudice

1. You and your friend just have finished reading *Pride and Prejudice* by Jane Austen. Among the four main characters in the book, Elizabeth, Jane, Lydia, and Darcy, your friend thinks that Darcy was the most mentioned. You, however, are certain it was Elizabeth. Obtain the full text of the novel from <http://www.gutenberg.org/cache/epub/42671/pg42671.txt> and save to your local folder. 
```{bash}
#| eval: false
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
```
Explain what `wget -nc` does. Do **not** put this text file `pg42671.txt` in Git. Complete the following loop to tabulate the number of times each of the four characters is mentioned using Linux commands.

**Solution: 'wget -nc' downloads a file from the web. '-nc' makes it so it will not download the file if a file with the same name already exists on my device.**


```{bash}
#| eval: false
for char in Elizabeth Jane Lydia Darcy
do
  echo $char:
  grep -w -o $char pg42671.txt | wc -l 
done
```
**Solution: Elizabeth is mentioned the most in this novel compared to the other names. Her name was mentioned 634 times, while Jane was mentioned 293 times, Lydia was mentioned 170 times, and Darcy was mentioned 416 times.**


2. What's the difference between the following two commands?
```{bash}
#| eval: false
echo 'hello, world' > test1.txt
```
and
```{bash}
#| eval: false
echo 'hello, world' >> test2.txt
```


**Solution: The first command will direct the output from one command to a file. It will either overwrite the contents of the file if it already exists or create the file and write 'hello,world' into it. The second command appends the output to a file. It will either add 'hello, world' to the file at the end if it already exists, or create a new file and write it there.** 


3. Using your favorite text editor (e.g., `vi`), type the following and save the file as `middle.sh`:

```{bash eval=FALSE}
#!/bin/sh
# Select lines from the middle of a file.
# Usage: bash middle.sh filename end_line num_lines
head -n "$2" "$1" | tail -n "$3"
```

Using `chmod` to make the file executable by the owner, and run

```{bash}
chmod u+x ~/middle.sh
```

```{bash}
ls -l ~/middle.sh
```

```{bash}
#| eval: false
~/middle.sh pg42671.txt 20 5
```
Explain the output. Explain the meaning of `"$1"`, `"$2"`, and `"$3"` in this shell script. Why do we need the first line of the shell script?

**Solution: `"$1"`, `"$2"`, and `"$3"` are the numerical order of the arguments. For the code '~/middle.sh pg42671.txt 20 5', `"$1` will be the first argument, which is 'pg42671.txt'. `"$2"` will be the second argument, which is "20". `"$3"` is the third argument, which is "5". The inputted arguments will be substituted in their appropriate positions in the 'middle.sh' code, so it will end up running: "head -n 20 pg42671.txt | tail -n 5". This line of code gets the first 20 lines in the 'pg42671.txt' file and then will return the final 5 lines of the first 20 lines in the file. You need the first line because it tells the respective system to use /bin/sh interpreter to run the 'middle.sh' script.**


## Q5. More fun with Linux

Try following commands in Bash and interpret the results: `cal`, `cal 2025`, `cal 9 1752` (anything unusual?), `date`, `hostname`, `arch`, `uname -a`, `uptime`, `who am i`, `who`, `w`, `id`, `last | head`, `echo {con,pre}{sent,fer}{s,ed}`, `time sleep 5`, `history | tail`.

```{bash}
cal
```
**'cal' gives the calendar dates for the current month, which is January 2025.**

```{bash}
cal 2025
```

**'cal 2025' gives the calendar dates of all of 2025.**


```{bash}
cal 9 1752
```
**'cal 9 1752' gives the calendar dates of September 1752. The dates 3-11 are missing in this month.**


```{bash}
date
```

**'date' gives the date, time in respective timezone, and year at the time of running the code.**

```{bash}
hostname
```

**'hostname' gives the device name.**

```{bash}
arch
```

**'arch' tells about my system's hardware architecture.**

```{bash}
uname -a
```

**'uname -a' gives all information about my system.**

```{bash}
uptime
```

**'uptime' shows the amount of time the system has been running. It also provides information about the current time, how many users are logged in, and the system's load averages.**

```{bash}
who am i
```

**'who am i' shows the username of the user who executed the command.**


```{bash}
who
```

**'who' shows more information about all the users. It gives the username, the device, and the appropriate log-in time.** 


```{bash}
w
```

**'w' gives more information about all the users. It gives: USER(username), TTY(terminal), FROM, LONGIN@, IDLE, and WHAT.** 


```{bash}
id
```

**'id' gives user ID, group ID, and groups that the user is a part of.**


```{bash}
last | head
```
**'last | head' shows the 10 most recent logins in the system and gives the username, terminal, date of login, and login duration.**



```{bash}
echo {con,pre}{sent,fer}{s,ed}
```

**'echo {con,pre}{sent,fer}{s,ed}' gives all the possible combinations of words that can be formed using the 3 sets of 2 words.**


```{bash}
time sleep 5 
```
**'time sleep 5' pauses the system for 5 seconds and provides information about how long it took to complete this command, how long it was in user mode, and how much it was in kernel mode.**


```{bash}
history | tail
```

**When I ran this code in my terminal, it gave me the past 10 commands I ran.**


## Q6. Book

1. Git clone the repository <https://github.com/christophergandrud/Rep-Res-Book> for the book _Reproducible Research with R and RStudio_ to your local machine. Do **not** put this repository within your homework repository `biostat-203b-2025-winter`.

2. Open the project by clicking `rep-res-3rd-edition.Rproj` and compile the book by clicking `Build Book` in the `Build` panel of RStudio. (Hint: I was able to build `git_book` and `epub_book` directly. For `pdf_book`, I needed to add a line `\usepackage{hyperref}` to the file `Rep-Res-Book/rep-res-3rd-edition/latex/preabmle.tex`.)

The point of this exercise is (1) to obtain the book for free and (2) to see an example how a complicated project such as a book can be organized in a reproducible way. Use `sudo apt install PKGNAME` to install required Ubuntu packages and `tlmgr install PKGNAME` to install missing TexLive packages.

For grading purpose, include a screenshot of Section 4.1.5 of the book here.